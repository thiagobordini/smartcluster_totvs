{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5322ee1e",
   "metadata": {},
   "source": [
    "#### **Setup Python**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ec1e93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação - Bibliotecas Python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, time, datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "import unicodedata\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Remoção de avisos do Python\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c45a74e",
   "metadata": {},
   "source": [
    "#### **Variáveis - Data Preprocessing TOTVS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c4ada0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável que armazena o caminho (path) das bases de dados presentes na camada raw\n",
    "path_raw = \"../data/raw\"\n",
    "\n",
    "# Variável que armazena o caminho (path) da camada \"processed\" onde as bases de dados processadas serão armazenadas inicialmente\n",
    "path_processed = \"../data/processed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2259ab",
   "metadata": {},
   "source": [
    "#### **Funções - Data Preprocessing TOTVS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06d982ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para padronizar strings: maiúsculas, remover acentos e espaços extras\n",
    "def padronizar_texto(coluna):\n",
    "    return (\n",
    "        coluna.astype(str)\n",
    "              .str.strip()\n",
    "              .str.upper()\n",
    "              .apply(lambda x: unicodedata.normalize(\"NFKD\", x)\n",
    "                      .encode(\"ascii\", errors=\"ignore\").decode(\"utf-8\"))\n",
    "    )\n",
    "\n",
    "def padronizar_valor(coluna):\n",
    "    return (\n",
    "        coluna.astype(str)\n",
    "            .replace(\"[R$ ]\", \"\", regex=True)\n",
    "            .str.replace(\".\", \"\", regex=False)\n",
    "            .str.replace(\",\", \".\", regex=False)\n",
    "            .astype(float)\n",
    "            .round(2)\n",
    "    )\n",
    "\n",
    "# Função para calcular a idade em meses\n",
    "def idade_contrato_meses(data_assinatura) -> float | int:\n",
    "    if pd.isnull(data_assinatura):\n",
    "        return np.nan\n",
    "    delta = relativedelta(pd.Timestamp.today(), data_assinatura)\n",
    "    return delta.years * 12 + delta.months\n",
    "\n",
    "# Função que classifica a nota nps\n",
    "def classificar_nps(nota):\n",
    "    if nota >= 9:\n",
    "        return \"PROMOTOR\"\n",
    "    elif nota >= 7:\n",
    "        return \"NEUTRO\"\n",
    "    else:\n",
    "        return \"DETRATOR\"\n",
    "\n",
    "def inserir_dataframe_postgres(df, nome_tabela, if_exists='replace', chunksize=100000):\n",
    "    # Carrega variáveis de ambiente\n",
    "    load_dotenv(dotenv_path=\"../.env\")\n",
    "\n",
    "    # Dados de conexão\n",
    "    usuario = os.getenv('DB_USER')\n",
    "    senha = os.getenv('DB_PASSWORD')\n",
    "    host = os.getenv('DB_HOST')\n",
    "    porta = os.getenv('DB_PORT')\n",
    "    banco = os.getenv('DB_NAME')\n",
    "\n",
    "    # Verifica se as variáveis estão preenchidas\n",
    "    if None in [usuario, senha, host, porta, banco]:\n",
    "        raise ValueError(\"Alguma variável de ambiente do banco não está definida.\")\n",
    "\n",
    "    # Cria engine de conexão\n",
    "    conn_string = f'postgresql+psycopg2://{usuario}:{senha}@{host}:{porta}/{banco}'\n",
    "    engine = create_engine(conn_string)\n",
    "\n",
    "    # Envia o DataFrame para o banco\n",
    "    try:\n",
    "        df.to_sql(\n",
    "            name=nome_tabela,\n",
    "            con=engine,\n",
    "            if_exists=if_exists,\n",
    "            index=False,\n",
    "            chunksize=chunksize,\n",
    "            method='multi'\n",
    "        )\n",
    "\n",
    "        with engine.connect() as conn:\n",
    "            # Conta número de linhas\n",
    "            result = conn.execute(text(f\"SELECT COUNT(*) FROM {nome_tabela}\"))\n",
    "            total_linhas = result.scalar()\n",
    "\n",
    "            # Conta número de colunas\n",
    "            result = conn.execute(text(f\"SELECT * FROM {nome_tabela} LIMIT 1\"))\n",
    "            total_colunas = len(result.keys())\n",
    "\n",
    "        print(f\"✅ Tabela '{nome_tabela}' inserida com sucesso!\")\n",
    "        print(f\"Total de linhas: {total_linhas:,} | Total de colunas: {total_colunas}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro ao inserir '{nome_tabela}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a2ee26",
   "metadata": {},
   "source": [
    "#### **Extract - Extração Dados Brutos (Raw)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a180325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura das bases de dados pertencentes há camada \"Row\"\n",
    "\n",
    "# Base de dados \"dados_clientes.csv\"\n",
    "dados_clientes = pd.read_csv(f\"{path_raw}/dados_clientes.csv\", sep=\";\")\n",
    "\n",
    "# Base de dados \"contratacoes_ultimos_12_meses.csv\"\n",
    "contratacoes = pd.read_csv(f\"{path_raw}/contratacoes_ultimos_12_meses.csv\", sep=\";\")\n",
    "\n",
    "# Base de dados \"clientes_desde.csv\"\n",
    "clientes_desde = pd.read_csv(f\"{path_raw}/clientes_desde.csv\", sep=\";\")\n",
    "\n",
    "# Base de dados \"historico.csv\"\n",
    "historico = pd.read_csv(f\"{path_raw}/historico.csv\", sep=\";\")\n",
    "\n",
    "# Base de dados \"mrr.csv\"\n",
    "mrr = pd.read_csv(f\"{path_raw}/mrr.csv\", sep=\";\")\n",
    "\n",
    "# Base de dados \"nps.nps_relacional.csv\"\n",
    "nps_relacional = pd.read_csv(f\"{path_raw}/nps_relacional.csv\", sep=';')\n",
    "\n",
    "# Base de dados \"nps_transacional_aquisicao.csv\"\n",
    "nps_aquisicao = pd.read_csv(f\"{path_raw}/nps_transacional_aquisicao.csv\", sep=\";\", encoding=\"latin1\")\n",
    "\n",
    "# Base de dados \"nps_transacional_implantacao.csv\"\n",
    "nps_implantacao = pd.read_csv(f\"{path_raw}/nps_transacional_implantacao.csv\", sep=\";\", encoding=\"latin1\")\n",
    "\n",
    "# Base de dados \"nps_transacional_onboarding.csv\"\n",
    "nps_onboarding = pd.read_csv(f\"{path_raw}/nps_transacional_onboarding.csv\", sep=\";\", encoding=\"latin1\")\n",
    "\n",
    "# Base de dados \"nps_transacional_produto.csv\"\n",
    "nps_produto = pd.read_csv(f\"{path_raw}/nps_transacional_produto.csv\", sep=\";\", encoding=\"latin1\")\n",
    "\n",
    "# Base de dados \"nps_transacional_suporte.csv\"\n",
    "nps_suporte = pd.read_csv(f\"{path_raw}/nps_transacional_suporte.csv\", sep=\";\")\n",
    "\n",
    "# Ordenação das bases de dados de \"telemetria_n.csv\"\n",
    "arquivos_telemetria = sorted(glob.glob(f\"{path_raw}/telemetria_*.csv\"))\n",
    "\n",
    "# Base de dados \"tickets.csv\"\n",
    "tickets = pd.read_csv(f\"{path_raw}/tickets.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004ab286",
   "metadata": {},
   "source": [
    "#### **Transform & Load - Pré-processamento dos dados para a camada \"Processed\" e PostgreSQL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82b4522",
   "metadata": {},
   "source": [
    "##### **Pré-processamento: dados_clientes.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "797fe2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tabela 'dados_clientes' inserida com sucesso!\n",
      "Total de linhas: 238,597 | Total de colunas: 20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pré-processamento da base de dados \"dados_clientes.csv\"\n",
    "\n",
    "# Cópia da base mãe\n",
    "df_dados_clientes = dados_clientes.copy(deep=True)\n",
    "\n",
    "# Preenchimento de colunas com registros nulos com 'NAO INFORMADO'\n",
    "colunas_nulo = {\n",
    "    \"DS_SUBSEGMENTO\": \"NAO INFORMADO\",\n",
    "    \"MARCA_TOTVS\": \"NAO INFORMADO\",\n",
    "    \"MODAL_COMERC\": \"NAO INFORMADO\",\n",
    "    \"PERIODICIDADE\": \"NAO INFORMADO\",\n",
    "    \"SITUACAO_CONTRATO\": \"NAO INFORMADO\"\n",
    "}\n",
    "for col, valor in colunas_nulo.items():\n",
    "    df_dados_clientes[col] = df_dados_clientes[col].fillna(valor)\n",
    "\n",
    "# Padronização em colunas de texto\n",
    "colunas_texto = [\n",
    "    \"DS_PROD\", \"DS_LIN_REC\", \"CIDADE\", \"DS_CNAE\", \"DS_SEGMENTO\",\n",
    "    \"DS_SUBSEGMENTO\", \"FAT_FAIXA\", \"MARCA_TOTVS\", \"MODAL_COMERC\",\n",
    "    \"PERIODICIDADE\", \"SITUACAO_CONTRATO\", \"UF\"\n",
    "]\n",
    "for col in colunas_texto:\n",
    "    df_dados_clientes[col] = padronizar_texto(df_dados_clientes[col])\n",
    "\n",
    "# Padronização e criação de faixas de valor para a coluna \"VL_TOTAL_CONTRATO\"\n",
    "df_dados_clientes[\"VL_TOTAL_CONTRATO\"] = padronizar_valor(df_dados_clientes[\"VL_TOTAL_CONTRATO\"])\n",
    "bins = [-float(\"inf\"), 0, 10000, 50000, 100000, 500000, 1000000, float(\"inf\")]\n",
    "labels = [\"ZERADO/NEGATIVO\", \"ATE 10K\", \"10K–50K\", \"50K–100K\", \"100K–500K\", \"500K–1M\", \"ACIMA DE 1M\"]\n",
    "df_dados_clientes[\"VL_TOTAL_CONTRATO_FAIXA\"] = pd.cut(df_dados_clientes[\"VL_TOTAL_CONTRATO\"], bins=bins, labels=labels)\n",
    "\n",
    "# Conversão da coluna \"DT_ASSINATURA_CONTRATO\" para datetime\n",
    "df_dados_clientes[\"DT_ASSINATURA_CONTRATO\"] = pd.to_datetime(df_dados_clientes[\"DT_ASSINATURA_CONTRATO\"], errors=\"coerce\")\n",
    "\n",
    "# Criação das colunas de ano e mês da assinatura\n",
    "df_dados_clientes[\"ANO_ASSINATURA\"] = df_dados_clientes[\"DT_ASSINATURA_CONTRATO\"].dt.year.astype('int64')\n",
    "df_dados_clientes[\"MES_ASSINATURA\"] = df_dados_clientes[\"DT_ASSINATURA_CONTRATO\"].dt.month.astype('int64')\n",
    "\n",
    "# Idade do contrato (em meses)\n",
    "df_dados_clientes[\"IDADE_CONTRATO_MESES\"] = df_dados_clientes[\"DT_ASSINATURA_CONTRATO\"].apply(idade_contrato_meses)\n",
    "\n",
    "# Renomeação de colunas para padrão snake_case\n",
    "df_dados_clientes.rename(columns={\n",
    "    \"CD_CLIENTE\": \"cliente_id\",\n",
    "    \"DS_PROD\": \"produto\",\n",
    "    \"DS_LIN_REC\": \"linha_receita\",\n",
    "    \"CIDADE\": \"cidade\",\n",
    "    \"DS_CNAE\": \"cnae\",\n",
    "    \"DS_SEGMENTO\": \"segmento\",\n",
    "    \"DS_SUBSEGMENTO\": \"subsegmento\",\n",
    "    \"FAT_FAIXA\": \"faixa_faturamento\",\n",
    "    \"MARCA_TOTVS\": \"marca_totvs\",\n",
    "    \"MODAL_COMERC\": \"modalidade_comercial\",\n",
    "    \"PAIS\": \"pais\",\n",
    "    \"PERIODICIDADE\": \"periodicidade\",\n",
    "    \"SITUACAO_CONTRATO\": \"situacao_contrato\",\n",
    "    \"UF\": \"uf\",\n",
    "    \"VL_TOTAL_CONTRATO\": \"valor_total_contrato\",\n",
    "    \"VL_TOTAL_CONTRATO_FAIXA\": \"faixa_valor_total_contrato\",\n",
    "    \"DT_ASSINATURA_CONTRATO\": \"data_assinatura_contrato\",\n",
    "    \"ANO_ASSINATURA\": \"ano_assinatura\",\n",
    "    \"MES_ASSINATURA\": \"mes_assinatura\",\n",
    "    \"IDADE_CONTRATO_MESES\": \"idade_contrato_meses\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Reorganização de colunas\n",
    "df_dados_clientes = df_dados_clientes[[\n",
    "    \"cliente_id\", \"produto\", \"linha_receita\", \"cnae\", \"segmento\", \"subsegmento\", \n",
    "    \"faixa_faturamento\", \"marca_totvs\", \"modalidade_comercial\", \"periodicidade\",\n",
    "    \"situacao_contrato\", \"cidade\", \"uf\", \"pais\", \"valor_total_contrato\", \n",
    "    \"faixa_valor_total_contrato\", \"data_assinatura_contrato\", \"ano_assinatura\", \n",
    "    \"mes_assinatura\", \"idade_contrato_meses\"\n",
    "]]\n",
    "\n",
    "# Exportação da base tratada para a camada \"processed\"\n",
    "df_dados_clientes.to_csv(f\"{path_processed}/dados_clientes.csv\", index=False)\n",
    "\n",
    "# Carregamento base de dados processada \"dados_clientes.csv\" no PostreSQL\n",
    "inserir_dataframe_postgres(df_dados_clientes, \"dados_clientes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5246dd4a",
   "metadata": {},
   "source": [
    "##### **Pré-processamento: contratacoes_ultimos_12_meses.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e3a63e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tabela 'contratacoes_ultimos_12_meses' inserida com sucesso!\n",
      "Total de linhas: 4,314 | Total de colunas: 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pré-processamento da base de dados \"contratacoes_ultimos_12_meses.csv\"\n",
    "\n",
    "# Cópia da base mãe\n",
    "df_contratacoes = contratacoes.copy(deep=True)\n",
    "\n",
    "# Padronização de valor para a coluna \"VLR_CONTRATACOES_12M\"\n",
    "df_contratacoes[\"VLR_CONTRATACOES_12M\"] = padronizar_valor(df_contratacoes[\"VLR_CONTRATACOES_12M\"])\n",
    "\n",
    "# Renomeação de colunas para padrão snake_case\n",
    "df_contratacoes.rename(columns={\n",
    "    \"CD_CLIENTE\": \"cliente_id\",\n",
    "    \"QTD_CONTRATACOES_12M\": \"qtd_contratacoes_12m\",\n",
    "    \"VLR_CONTRATACOES_12M\": \"vlr_contratacoes_12m\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Reorganização de colunas\n",
    "df_contratacoes = df_contratacoes[[\n",
    "    \"cliente_id\", \"qtd_contratacoes_12m\", \"vlr_contratacoes_12m\"\n",
    "]]\n",
    "\n",
    "# Exportação da base tratada para a camada \"processed\"\n",
    "df_contratacoes.to_csv(f\"{path_processed}/contratacoes_ultimos_12_meses.csv\", index=False)\n",
    "\n",
    "# Carregamento base de dados processada \"contratacoes_ultimos_12_meses.csv\" no PostreSQL\n",
    "inserir_dataframe_postgres(df_contratacoes, \"contratacoes_ultimos_12_meses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e67931e",
   "metadata": {},
   "source": [
    "##### **Pré-processamento: clientes_desde.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "697d591b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tabela 'clientes_desde' inserida com sucesso!\n",
      "Total de linhas: 10,615 | Total de colunas: 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pré-processamento da base de dados \"clientes_desde.csv\"\n",
    "\n",
    "# Cópia da base mãe\n",
    "df_clientes_desde = clientes_desde.copy(deep=True)\n",
    "\n",
    "# Renomeação de colunas para padrão snake_case\n",
    "df_clientes_desde.rename(columns={\n",
    "    \"CLIENTE\": \"cliente_id\",\n",
    "    \"CLIENTE_DESDE\": \"cliente_desde\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Conversão da coluna \"cliente_desde\" para datetime e criação de colunas derivadas\n",
    "df_clientes_desde[\"cliente_desde\"] = pd.to_datetime(df_clientes_desde[\"cliente_desde\"], errors=\"coerce\")\n",
    "df_clientes_desde[\"ano_inicio\"] = df_clientes_desde[\"cliente_desde\"].dt.year.astype('int64')\n",
    "df_clientes_desde[\"tempo_com_empresa_anos\"] = (\n",
    "    (pd.Timestamp(\"today\") - df_clientes_desde[\"cliente_desde\"]).dt.days / 365\n",
    ").round(1)\n",
    "\n",
    "# Reorganização de colunas\n",
    "df_clientes_desde = df_clientes_desde[[\n",
    "    \"cliente_id\", \"cliente_desde\", \"ano_inicio\", \"tempo_com_empresa_anos\"\n",
    "]]\n",
    "\n",
    "# Exportação da base tratada para a camada \"processed\"\n",
    "df_clientes_desde.to_csv(f\"{path_processed}/clientes_desde.csv\", index=False)\n",
    "\n",
    "# Carregamento base de dados processada \"clientes_desde.csv\" no PostreSQL\n",
    "inserir_dataframe_postgres(df_clientes_desde, \"clientes_desde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29143f0b",
   "metadata": {},
   "source": [
    "##### **Pré-processamento: historico.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a46b10aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tabela 'historico' inserida com sucesso!\n",
      "Total de linhas: 22,740 | Total de colunas: 18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pré-processamento da base de dados \"historico.csv\"\n",
    "\n",
    "# Cópia da base mãe\n",
    "df_historico = historico.copy(deep=True)\n",
    "\n",
    "# Renomeação de colunas para padrão snake_case\n",
    "df_historico.rename(columns={\n",
    "    \"NR_PROPOSTA\": \"nr_proposta\",\n",
    "    \"ITEM_PROPOSTA\": \"item_proposta\",\n",
    "    \"DT_UPLOAD\": \"data_upload\",\n",
    "    \"HOSPEDAGEM\": \"hospedagem\",\n",
    "    \"CD_CLI\": \"cliente_id\",\n",
    "    \"FAT_FAIXA\": \"faixa_faturamento\",\n",
    "    \"CD_PROD\": \"produto_id\",\n",
    "    \"QTD\": \"quantidade\",\n",
    "    \"MESES_BONIF\": \"meses_bonificacao\",\n",
    "    \"VL_PCT_DESC_TEMP\": \"pct_desc_temp\",\n",
    "    \"VL_PCT_DESCONTO\": \"pct_desconto\",\n",
    "    \"PRC_UNITARIO\": \"preco_unitario\",\n",
    "    \"VL_DESCONTO_TEMPORARIO\": \"valor_desc_temp\",\n",
    "    \"VL_TOTAL\": \"valor_total\",\n",
    "    \"VL_FULL\": \"valor_full\",\n",
    "    \"VL_DESCONTO\": \"valor_desconto\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Padronização de textos\n",
    "colunas_texto = [\"faixa_faturamento\", \"hospedagem\"]\n",
    "for col in colunas_texto:\n",
    "    df_historico[col] = padronizar_texto(df_historico[col])\n",
    "\n",
    "# Conversão da coluna \"data_upload\" para datetime e criação de colunas derivadas\n",
    "df_historico[\"data_upload\"] = pd.to_datetime(df_historico[\"data_upload\"], errors=\"coerce\")\n",
    "df_historico[\"ano_upload\"] = df_historico[\"data_upload\"].dt.year.astype('int64')\n",
    "df_historico[\"mes_upload\"] = df_historico[\"data_upload\"].dt.month.astype('int64')\n",
    "\n",
    "# Padronização e conversão de valores numéricos\n",
    "colunas_valores = [\n",
    "    \"quantidade\", \"pct_desc_temp\", \"pct_desconto\", \"preco_unitario\",\n",
    "    \"valor_desc_temp\", \"valor_total\", \"valor_full\", \"valor_desconto\"\n",
    "]\n",
    "for col in colunas_valores:\n",
    "    df_historico[col] = padronizar_valor(df_historico[col])\n",
    "\n",
    "# Reorganização de colunas\n",
    "df_historico = df_historico[[\n",
    "    \"nr_proposta\", \"item_proposta\", \"cliente_id\", \"produto_id\", \"data_upload\", \"ano_upload\", \"mes_upload\",\n",
    "    \"hospedagem\", \"faixa_faturamento\", \"quantidade\", \"meses_bonificacao\", \"pct_desc_temp\", \"pct_desconto\", \n",
    "    \"preco_unitario\", \"valor_desc_temp\", \"valor_total\", \"valor_full\", \"valor_desconto\"\n",
    "]]\n",
    "\n",
    "# Exportação da base tratada para a camada \"processed\"\n",
    "df_historico.to_csv(f\"{path_processed}/historico.csv\", index=False)\n",
    "\n",
    "# Carregamento base de dados processada \"historico.csv\" no PostreSQL\n",
    "inserir_dataframe_postgres(df_historico, \"historico\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba18a3d",
   "metadata": {},
   "source": [
    "##### **Pré-processamento: mrr.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3403b790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tabela 'mrr' inserida com sucesso!\n",
      "Total de linhas: 7,309 | Total de colunas: 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pré-processamento da base de dados \"mrr.csv\"\n",
    "\n",
    "# Cópia da base mãe\n",
    "df_mrr = mrr.copy(deep=True)\n",
    "\n",
    "# Renomeação de colunas para padrão snake_case\n",
    "df_mrr.rename(columns={\n",
    "    \"CLIENTE\": \"cliente_id\",\n",
    "    \"MRR_12M\": \"mrr_12m\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Arredondar MRR para 2 casas decimais e criação de faixas de MRR\n",
    "df_mrr[\"mrr_12m\"] = df_mrr[\"mrr_12m\"].round(2)\n",
    "bins = [-0.01, 0, 1000, 5000, 10000, 50000, 100000, float(\"inf\")]\n",
    "labels = [\"ZERADO\", \"ATE 1K\", \"1K–5K\", \"5K–10K\", \"10K–50K\", \"50K–100K\", \"ACIMA DE 100K\"]\n",
    "df_mrr[\"faixa_mrr_12m\"] = pd.cut(df_mrr[\"mrr_12m\"], bins=bins, labels=labels)\n",
    "\n",
    "# Reogranização de colunas\n",
    "df_mrr = df_mrr[[\n",
    "    \"cliente_id\", \"mrr_12m\", \"faixa_mrr_12m\"\n",
    "]]\n",
    "\n",
    "# Exportação da base tratada para a camada \"processed\"\n",
    "df_mrr.to_csv(f\"{path_processed}/mrr.csv\", index=False)\n",
    "\n",
    "# Carregamento base de dados processada \"mrr.csv\" no PostreSQL\n",
    "inserir_dataframe_postgres(df_mrr, \"mrr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced84609",
   "metadata": {},
   "source": [
    "##### **Pré-processamento: nps_relacional.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c4c7c624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tabela 'nps_relacional' inserida com sucesso!\n",
      "Total de linhas: 14,143 | Total de colunas: 12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pré-processamento da base de dados \"nps_relacional.csv\"\n",
    "\n",
    "# Cópia da base mãe\n",
    "df_nps_relacional = nps_relacional.copy(deep=True)\n",
    "\n",
    "# Renomeação de colunas para padrão snake_case\n",
    "df_nps_relacional.rename(columns={\n",
    "    \"respondedAt\": \"data_resposta\",\n",
    "    \"metadata_codcliente\": \"cliente_id\",\n",
    "    \"resposta_NPS\": \"nota_nps\",\n",
    "    \"resposta_unidade\": \"nota_unidade\",\n",
    "    \"Nota_SupTec_Agilidade\": \"nota_suptec_agilidade\",\n",
    "    \"Nota_SupTec_Atendimento\": \"nota_suptec_atendimento\",\n",
    "    \"Nota_Comercial\": \"nota_comercial\",\n",
    "    \"Nota_Custos\": \"nota_custos\",\n",
    "    \"Nota_AdmFin_Atendimento\": \"nota_admfin_atendimento\",\n",
    "    \"Nota_Software\": \"nota_software\",\n",
    "    \"Nota_Software_Atualizacao\": \"nota_software_atualizacao\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Conversão da coluna \"data_resposta\" para datetime e conversão de tipos\n",
    "df_nps_relacional[\"data_resposta\"] = pd.to_datetime(df_nps_relacional[\"data_resposta\"], errors=\"coerce\")\n",
    "\n",
    "# Conversão da coluna \"cliente_id\" para string\n",
    "df_nps_relacional[\"cliente_id\"] = df_nps_relacional[\"cliente_id\"].astype(str)\n",
    "\n",
    "# Conversão da coluna \"nota_nps\" para int64\n",
    "df_nps_relacional[\"nota_nps\"] = df_nps_relacional[\"nota_nps\"].astype('int64')\n",
    "\n",
    "# Aplicação da função de classificação da nota NPS\n",
    "df_nps_relacional[\"categoria_nps\"] = df_nps_relacional[\"nota_nps\"].apply(classificar_nps)\n",
    "\n",
    "# Padronização e conversão de demais colunas de nota para float\n",
    "colunas_nota = [\n",
    "    \"nota_unidade\", \"nota_suptec_agilidade\", \"nota_suptec_atendimento\", \"nota_comercial\", \n",
    "    \"nota_custos\", \"nota_admfin_atendimento\", \"nota_software\", \"nota_software_atualizacao\"]\n",
    "df_nps_relacional[colunas_nota] = df_nps_relacional[colunas_nota].astype(float)\n",
    "\n",
    "# Reorganização de colunas\n",
    "df_nps_relacional = df_nps_relacional[[\n",
    "    \"cliente_id\", \"data_resposta\", \"nota_nps\", \"nota_unidade\", \n",
    "    \"nota_suptec_agilidade\", \"nota_suptec_atendimento\", \n",
    "    \"nota_comercial\", \"nota_custos\", \"nota_admfin_atendimento\", \n",
    "    \"nota_software\", \"nota_software_atualizacao\", \"categoria_nps\"\n",
    "]]\n",
    "\n",
    "# Exportação da base tratada para a camada \"processed\"\n",
    "df_nps_relacional.to_csv(f\"{path_processed}/nps_relacional.csv\", index=False)\n",
    "\n",
    "# Carregamento base de dados processada \"nps_relacional.csv\" no PostreSQL\n",
    "inserir_dataframe_postgres(df_nps_relacional, \"nps_relacional\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26696cf5",
   "metadata": {},
   "source": [
    "##### **Pré-processamento: nps_transacional_aquisicao.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "adfdcd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tabela 'nps_transacional_aquisicao' inserida com sucesso!\n",
      "Total de linhas: 178 | Total de colunas: 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pré-processamento da base de dados \"nps_transacional_aquisicao.csv\"\n",
    "\n",
    "# Cópia da base mãe\n",
    "df_nps_aquisicao = nps_aquisicao.copy(deep=True)\n",
    "\n",
    "# Renomear colunas para padrão snake_case\n",
    "df_nps_aquisicao.rename(columns={\n",
    "    \"Cód. Cliente\": \"cliente_id\",\n",
    "    \"Data da Resposta\": \"data_resposta\",\n",
    "    \"Nota NPS\": \"nota_nps\",\n",
    "    \"Nota Agilidade\": \"nota_agilidade\",\n",
    "    \"Nota Conhecimento\": \"nota_conhecimento\",\n",
    "    \"Nota Custo\": \"nota_custo\",\n",
    "    \"Nota Facilidade\": \"nota_facilidade\",\n",
    "    \"Nota Flexibilidade\": \"nota_flexibilidade\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Preenchendo valores nulos da coluna \"cliente_id\" e transformando para string\n",
    "df_nps_aquisicao[\"cliente_id\"] = df_nps_aquisicao[\"cliente_id\"].fillna(\"NAO INFORMADO\").astype(str)\n",
    "\n",
    "# Conversão da coluna \"data_resposta\" para datetime\n",
    "df_nps_aquisicao[\"data_resposta\"] = pd.to_datetime(df_nps_aquisicao[\"data_resposta\"], errors=\"coerce\")\n",
    "\n",
    "# Conversão da coluna \"nota_nps\" para int64\n",
    "df_nps_aquisicao[\"nota_nps\"] = df_nps_aquisicao[\"nota_nps\"].astype('int64')\n",
    "\n",
    "# Aplicação da função de classificação da nota NPS\n",
    "df_nps_aquisicao[\"categoria_nps\"] = df_nps_aquisicao[\"nota_nps\"].apply(classificar_nps)\n",
    "\n",
    "# Padronização e conversão de demais colunas de nota para float\n",
    "colunas_nota = [\"nota_agilidade\", \"nota_conhecimento\", \"nota_custo\", \"nota_facilidade\", \"nota_flexibilidade\"]\n",
    "df_nps_aquisicao[colunas_nota] = df_nps_aquisicao[colunas_nota].astype(float)\n",
    "\n",
    "# Exportação da base tratada para a camada \"processed\"\n",
    "df_nps_aquisicao.to_csv(f\"{path_processed}/nps_transacional_aquisicao.csv\", index=False)\n",
    "\n",
    "# Carregamento base de dados processada \"nps_transacional_aquisicao.csv\" no PostreSQL\n",
    "inserir_dataframe_postgres(df_nps_aquisicao, \"nps_transacional_aquisicao\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4972efe1",
   "metadata": {},
   "source": [
    "##### **Pré-processamento: nps_transacional_implantacao.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4705478a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tabela 'nps_transacional_implantacao' inserida com sucesso!\n",
      "Total de linhas: 662 | Total de colunas: 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pré-processamento da base de dados \"nps_transacional_implantacao.csv\"\n",
    "\n",
    "# Cópia da base mãe\n",
    "df_nps_implatacao = nps_implantacao.copy(deep=True)\n",
    "\n",
    "# Renomear colunas para padrão snake_case\n",
    "df_nps_implatacao.rename(columns={\n",
    "    \"Cód. Cliente\": \"cliente_id\",\n",
    "    \"Data da Resposta\": \"data_resposta\",\n",
    "    \"Nota NPS\": \"nota_nps\",\n",
    "    \"Nota Metodologia\": \"nota_metodologia\",\n",
    "    \"Nota Gestao\": \"nota_gestao\",\n",
    "    \"Nota Conhecimento\": \"nota_conhecimento\",\n",
    "    \"Nota Qualidade\": \"nota_qualidade\",\n",
    "    \"Nota Comunicacao\": \"nota_comunicacao\",\n",
    "    \"Nota Prazos\": \"nota_prazos\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Preenchendo valores nulos da coluna \"cliente_id\" e transformando para string\n",
    "df_nps_implatacao[\"cliente_id\"] = df_nps_implatacao[\"cliente_id\"].fillna(\"NAO INFORMADO\").astype(str)\n",
    "\n",
    "# Conversão da coluna \"data_resposta\" para datetime\n",
    "df_nps_implatacao[\"data_resposta\"] = pd.to_datetime(df_nps_implatacao[\"data_resposta\"], errors=\"coerce\")\n",
    "\n",
    "# Conversão da coluna \"nota_nps\" para int64\n",
    "df_nps_implatacao[\"nota_nps\"] = df_nps_implatacao[\"nota_nps\"].astype('int64')\n",
    "\n",
    "# Aplicação da função de classificação da nota NPS\n",
    "df_nps_implatacao[\"categoria_nps\"] = df_nps_implatacao[\"nota_nps\"].apply(classificar_nps)\n",
    "\n",
    "# Padronização e conversão de demais colunas de nota para float\n",
    "colunas_nota = [\"nota_metodologia\", \"nota_gestao\", \"nota_conhecimento\", \"nota_qualidade\", \"nota_comunicacao\", \"nota_prazos\"]\n",
    "df_nps_implatacao[colunas_nota] = df_nps_implatacao[colunas_nota].astype(float)\n",
    "\n",
    "# Exportação da base tratada para a camada \"processed\"\n",
    "df_nps_implatacao.to_csv(f\"{path_processed}/nps_transacional_implantacao.csv\", index=False)\n",
    "\n",
    "# Carregamento base de dados processada \"nps_transacional_implantacao.csv\" no PostgreSQL\n",
    "inserir_dataframe_postgres(df_nps_implatacao, \"nps_transacional_implantacao\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8a37a3",
   "metadata": {},
   "source": [
    "##### **Pré-processamento: nps_transacional_onboarding.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "586f7e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tabela 'nps_transacional_onboarding' inserida com sucesso!\n",
      "Total de linhas: 208 | Total de colunas: 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pré-processamento da base de dados \"nps_transacional_onboarding.csv\"\n",
    "\n",
    "# Cópia da base mãe\n",
    "df_nps_onboarding = nps_onboarding.copy(deep=True)\n",
    "\n",
    "# Renomear colunas para padrão snake_case e nomes mais limpos\n",
    "df_nps_onboarding.rename(columns={\n",
    "    \"Data de resposta\": \"data_resposta\",\n",
    "    \"Cod Cliente\": \"cliente_id\",\n",
    "    \"Em uma escala de 0 a 10, quanto você recomenda o Onboarding da TOTVS para um amigo ou colega?.\": \"nota_nps\",\n",
    "    \"Em uma escala de 0 a 10, o quanto você acredita que o atendimento CS Onboarding ajudou no início da sua trajetória com a TOTVS?\": \"nota_ajuda_inicio\",\n",
    "    \"- Duração do tempo na realização da reunião de Onboarding;\": \"nota_tempo_reuniao\",\n",
    "    \"- Clareza no acesso aos canais de comunicação da TOTVS;\": \"nota_clareza_comunicacao\",\n",
    "    \"- Clareza nas informações em geral transmitidas pelo CS que lhe atendeu no Onboarding;\": \"nota_clareza_informacao\",\n",
    "    \"- Expectativas atendidas no Onboarding da TOTVS.\": \"nota_expectativa\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Preenchendo valores nulos da coluna \"cliente_id\" e transformando para string\n",
    "df_nps_onboarding[\"cliente_id\"] = df_nps_onboarding[\"cliente_id\"].fillna(\"NAO INFORMADO\").astype(str)\n",
    "\n",
    "# Conversão da coluna \"data_resposta\" para datetime\n",
    "df_nps_onboarding[\"data_resposta\"] = pd.to_datetime(df_nps_onboarding[\"data_resposta\"], errors=\"coerce\")\n",
    "\n",
    "# Conversão da coluna \"nota_nps\" para int64\n",
    "df_nps_onboarding[\"nota_nps\"] = df_nps_onboarding[\"nota_nps\"].astype('int64')\n",
    "\n",
    "# Aplicação da função de classificação da nota NPS\n",
    "df_nps_onboarding[\"categoria_nps\"] = df_nps_onboarding[\"nota_nps\"].apply(classificar_nps)\n",
    "\n",
    "# Garantir que demais notas sejam float\n",
    "colunas_nota = [\"nota_ajuda_inicio\", \"nota_tempo_reuniao\", \"nota_clareza_comunicacao\", \"nota_clareza_informacao\", \"nota_expectativa\"]\n",
    "df_nps_onboarding[colunas_nota] = df_nps_onboarding[colunas_nota].astype(float)\n",
    "\n",
    "# Reorganização de colunas\n",
    "df_nps_onboarding = df_nps_onboarding[[\n",
    "    'cliente_id', 'data_resposta', 'nota_nps', 'nota_ajuda_inicio', 'nota_tempo_reuniao', \n",
    "    'nota_clareza_comunicacao', 'nota_clareza_informacao', 'nota_expectativa', 'categoria_nps'\n",
    "]]\n",
    "\n",
    "# Exportação da base tratada para a camada \"processed\"\n",
    "df_nps_onboarding.to_csv(f\"{path_processed}/nps_transacional_onboarding.csv\", index=False)\n",
    "\n",
    "# Carregamento base de dados processada \"nps_transacional_onboarding.csv\" no PostgreSQL\n",
    "inserir_dataframe_postgres(df_nps_onboarding, \"nps_transacional_onboarding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2077e6",
   "metadata": {},
   "source": [
    "##### **Pré-processamento: nps_transacional_produto.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "81822045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tabela 'nps_transacional_produto' inserida com sucesso!\n",
      "Total de linhas: 113,207 | Total de colunas: 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pré-processamento da base de dados \"nps_transacional_produto.csv\"\n",
    "\n",
    "# Cópia da base mãe\n",
    "df_nps_produto = nps_produto.copy(deep=True)\n",
    "\n",
    "# Renomear colunas para padrão snake_case e nomes mais limpos\n",
    "df_nps_produto.rename(columns={\n",
    "    \"Data da Resposta\": \"data_resposta\",\n",
    "    \"Linha de Produto\": \"linha_produto\",\n",
    "    \"Nome do Produto\": \"nome_produto\",\n",
    "    \"Nota\": \"nota_nps\",\n",
    "    \"Cód. T\": \"cliente_id\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Organizando colunas\n",
    "df_nps_produto = df_nps_produto[[\n",
    "    'cliente_id', 'data_resposta', 'linha_produto', 'nome_produto', 'nota_nps'\n",
    "]]\n",
    "\n",
    "# Conversão da coluna \"data_resposta\" para datetime\n",
    "df_nps_produto[\"data_resposta\"] = pd.to_datetime(df_nps_produto[\"data_resposta\"], errors=\"coerce\")\n",
    "\n",
    "# Padronização de texto nas colunas \"linha_produto\" e \"nome_produto\"\n",
    "colunas_texto_produto = [\"linha_produto\", \"nome_produto\"]\n",
    "for col in colunas_texto_produto:\n",
    "    df_nps_produto[col] = padronizar_texto(df_nps_produto[col])\n",
    "\n",
    "# Conversão da coluna \"cliente_id\" para string\n",
    "df_nps_produto[\"cliente_id\"] = df_nps_produto[\"cliente_id\"].astype(str)\n",
    "\n",
    "# Conversão da coluna \"nota_nps\" para int64\n",
    "df_nps_produto[\"nota_nps\"] = df_nps_produto[\"nota_nps\"].astype('int64')\n",
    "\n",
    "# Aplicação da função de classificação da nota NPS\n",
    "df_nps_produto[\"categoria_nps\"] = df_nps_produto[\"nota_nps\"].apply(classificar_nps)\n",
    "\n",
    "# Exportação da base tratada para a camada \"processed\"\n",
    "df_nps_produto.to_csv(f\"{path_processed}/nps_transacional_produto.csv\", index=False)\n",
    "\n",
    "# Carregamento base de dados processada \"nps_transacional_produto.csv\" no PostgreSQL\n",
    "inserir_dataframe_postgres(df_nps_produto, \"nps_transacional_produto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde509a5",
   "metadata": {},
   "source": [
    "##### **Pré-processamento: nps_transacional_suporte.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b8117f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tabela 'nps_transacional_suporte' inserida com sucesso!\n",
      "Total de linhas: 74,794 | Total de colunas: 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pré-processamento da base de dados \"nps_transacional_suporte.csv\"\n",
    "\n",
    "# Cópia da base mãe\n",
    "df_nps_suporte = nps_suporte.copy(deep=True)\n",
    "\n",
    "# Renomear colunas para padrão snake_case e nomes mais limpos\n",
    "df_nps_suporte.rename(columns={\n",
    "    \"ticket\": \"ticket_id\",\n",
    "    \"resposta_NPS\": \"nota_nps\",\n",
    "    \"grupo_NPS\": \"categoria_nps\",\n",
    "    \"Nota_ConhecimentoAgente\": \"nota_conhecimento_agente\",\n",
    "    \"Nota_Solucao\": \"nota_solucao\",\n",
    "    \"Nota_TempoRetorno\": \"nota_tempo_retorno\",\n",
    "    \"Nota_Facilidade\": \"nota_facilidade\",\n",
    "    \"Nota_Satisfacao\": \"nota_satisfacao\",\n",
    "    \"cliente\": \"cliente_id\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Padronizando texto na coluna \"categoria_nps\" e substituindo \"PASSIVO\" por \"NEUTRO\"\n",
    "df_nps_suporte[\"categoria_nps\"] = padronizar_texto(df_nps_suporte[\"categoria_nps\"])\n",
    "df_nps_suporte[\"categoria_nps\"] = df_nps_suporte[\"categoria_nps\"].replace(\"PASSIVO\", \"NEUTRO\")\n",
    "\n",
    "# Conversão das colunas \"tickets_id\" e \"nota_nps\" para int64\n",
    "colunas_valores_inteiros = [\"ticket_id\", \"nota_nps\"]\n",
    "for col in colunas_valores_inteiros:\n",
    "    df_nps_suporte[col] = df_nps_suporte[col].astype('int64')\n",
    "\n",
    "# Conversão da coluna \"cliente_id\" para string\n",
    "df_nps_suporte[\"cliente_id\"] = df_nps_suporte[\"cliente_id\"].astype(str)\n",
    "\n",
    "# Organizando colunas\n",
    "df_nps_suporte = df_nps_suporte[[\n",
    "    \"cliente_id\", \"ticket_id\", \"nota_nps\", \"nota_conhecimento_agente\", \n",
    "    \"nota_solucao\", \"nota_tempo_retorno\", \"nota_facilidade\", \"nota_satisfacao\", \n",
    "    \"categoria_nps\"\n",
    "]]\n",
    "\n",
    "# Exportação da base tratada para a camada \"processed\"\n",
    "df_nps_suporte.to_csv(f\"{path_processed}/nps_transacional_suporte.csv\", index=False)\n",
    "\n",
    "# Carregamento base de dados processada \"nps_transacional_suporte.csv\" no PostgreSQL\n",
    "inserir_dataframe_postgres(df_nps_suporte, \"nps_transacional_suporte\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d51f3e4",
   "metadata": {},
   "source": [
    "##### **Pré-processamento: telemetria_1.csv a telemetria_11.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f504161e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tabela 'telemetria_1' inserida com sucesso!\n",
      "Total de linhas: 2,535,221 | Total de colunas: 9\n",
      "\n",
      "✅ Tabela 'telemetria_10' inserida com sucesso!\n",
      "Total de linhas: 1,884,789 | Total de colunas: 9\n",
      "\n",
      "✅ Tabela 'telemetria_11' inserida com sucesso!\n",
      "Total de linhas: 3,485,570 | Total de colunas: 9\n",
      "\n",
      "✅ Tabela 'telemetria_2' inserida com sucesso!\n",
      "Total de linhas: 3,298,672 | Total de colunas: 9\n",
      "\n",
      "✅ Tabela 'telemetria_3' inserida com sucesso!\n",
      "Total de linhas: 2,047,906 | Total de colunas: 9\n",
      "\n",
      "✅ Tabela 'telemetria_4' inserida com sucesso!\n",
      "Total de linhas: 1,574,418 | Total de colunas: 9\n",
      "\n",
      "✅ Tabela 'telemetria_5' inserida com sucesso!\n",
      "Total de linhas: 1,681,694 | Total de colunas: 9\n",
      "\n",
      "✅ Tabela 'telemetria_6' inserida com sucesso!\n",
      "Total de linhas: 4,939,234 | Total de colunas: 9\n",
      "\n",
      "✅ Tabela 'telemetria_7' inserida com sucesso!\n",
      "Total de linhas: 3,017,771 | Total de colunas: 9\n",
      "\n",
      "✅ Tabela 'telemetria_8' inserida com sucesso!\n",
      "Total de linhas: 3,234,597 | Total de colunas: 9\n",
      "\n",
      "✅ Tabela 'telemetria_9' inserida com sucesso!\n",
      "Total de linhas: 3,104,325 | Total de colunas: 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pré-processamento das bases de dados \"telemetria_n.csv\"\n",
    "\n",
    "for arquivo_telemetria in arquivos_telemetria:\n",
    "    df_telemetria = pd.read_csv(arquivo_telemetria)\n",
    "\n",
    "    # Conversão da colunas_nota 'referencedatestart' para datetime e criação de colunas derivadas\n",
    "    df_telemetria['referencedatestart'] = pd.to_datetime(df_telemetria['referencedatestart'], errors='coerce')\n",
    "    df_telemetria[\"ano_referencia\"] = df_telemetria[\"referencedatestart\"].dt.year.astype('int64')\n",
    "    df_telemetria[\"mes_referencia\"] = df_telemetria[\"referencedatestart\"].dt.month.astype('int64')\n",
    "\n",
    "    # Padronização de texto na coluna 'statuslicenca' e preenchenado valores nulos com 'NAO INFORMADO'\n",
    "    df_telemetria['statuslicenca'] = padronizar_texto(df_telemetria['statuslicenca'])\n",
    "    df_telemetria['statuslicenca'] = df_telemetria['statuslicenca'].replace('NAN', 'NAO INFORMADO')\n",
    "\n",
    "    # Conversão da coluna 'eventduration' para float e arredondamento para 2 casas decimais\n",
    "    df_telemetria['eventduration'] = df_telemetria['eventduration'].astype(float).round(2)\n",
    "\n",
    "    # Remoção de colunas irrelevantes (tcloud e clienteprime, pois são totalmente nulas)\n",
    "    df_telemetria.drop(columns=['tcloud', 'clienteprime'], inplace=True)\n",
    "\n",
    "    # Renomeação de colunas para padrão snake_case\n",
    "    df_telemetria.rename(columns={\n",
    "        'clienteid': 'cliente_id',\n",
    "        'eventduration': 'duracao_evento',\n",
    "        'moduloid': 'modulo_id',\n",
    "        'productlineid': 'linha_produto_id',\n",
    "        'referencedatestart': 'data_referencia',\n",
    "        'slotid': 'slot_id',\n",
    "        'statuslicenca': 'status_licenca'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Organizando colunas\n",
    "    df_telemetria = df_telemetria[[\n",
    "        'cliente_id', 'data_referencia', 'ano_referencia', 'mes_referencia', \n",
    "        'duracao_evento', 'modulo_id', 'linha_produto_id', 'slot_id', 'status_licenca'\n",
    "    ]]\n",
    "\n",
    "    # Exportação da base tratada para a camada \"processed\"\n",
    "    df_telemetria.to_csv(f\"{path_processed}/{arquivo_telemetria.split(\"\\\\\")[1]}\", index=False)\n",
    "    \n",
    "    # Carregamento base de dados processada \"telemetria_[n].csv\" no PostgreSQL\n",
    "    inserir_dataframe_postgres(df_telemetria, f\"telemetria_{re.findall(r'\\d+', arquivo_telemetria)[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e237e59a",
   "metadata": {},
   "source": [
    "##### **Pré-processamento: tickets.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9d3b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tabela 'tickets' inserida com sucesso!\n",
      "Total de linhas: 976,364 | Total de colunas: 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pré-processamento da base de dados \"nps_transacional_suporte.csv\"\n",
    "\n",
    "# Cópia da base mãe\n",
    "df_tickets = tickets.copy(deep=True)\n",
    "\n",
    "# Conversão das colunas 'DT_CRIACAO' e 'DT_ATUALIZACAO' para datetime e criação de colunas derivadas\n",
    "df_tickets['DT_CRIACAO'] = pd.to_datetime(df_tickets['DT_CRIACAO'], errors='coerce')\n",
    "df_tickets['DT_ATUALIZACAO'] = pd.to_datetime(df_tickets['DT_ATUALIZACAO'], errors='coerce')\n",
    "df_tickets['ano_criacao'] = df_tickets['DT_CRIACAO'].dt.year.astype('int64')\n",
    "df_tickets['mes_criacao'] = df_tickets['DT_CRIACAO'].dt.month.astype('int64')\n",
    "\n",
    "# Padronização de texto nas colunas\n",
    "colunas_texto = ['NOME_GRUPO', 'TIPO_TICKET', 'STATUS_TICKET', 'PRIORIDADE_TICKET']\n",
    "for col in colunas_texto:\n",
    "    df_tickets[col] = padronizar_texto(df_tickets[col])\n",
    "\n",
    "# Renomeação de colunas para padrão snake_case\n",
    "df_tickets.rename(columns={\n",
    "    'CODIGO_ORGANIZACAO': 'cliente_id',\n",
    "    'NOME_GRUPO': 'nome_grupo',\n",
    "    'TIPO_TICKET': 'tipo_ticket',\n",
    "    'STATUS_TICKET': 'status_ticket',\n",
    "    'DT_CRIACAO': 'data_criacao',\n",
    "    'DT_ATUALIZACAO': 'data_atualizacao',\n",
    "    'BK_TICKET': 'ticket_id',\n",
    "    'PRIORIDADE_TICKET': 'prioridade_ticket'\n",
    "}, inplace=True)\n",
    "\n",
    "# Reorganização das colunas\n",
    "df_tickets = df_tickets[[\n",
    "    'ticket_id', 'cliente_id', 'nome_grupo', 'tipo_ticket', \n",
    "    'status_ticket', 'prioridade_ticket', 'data_criacao', \n",
    "    'ano_criacao', 'mes_criacao', 'data_atualizacao'\n",
    "]]\n",
    "\n",
    "# Exportação da base tratada para a camada \"processed\"\n",
    "df_tickets.to_csv(f\"{path_processed}/tickets.csv\", index=False)\n",
    "\n",
    "# Carregamento base de dados processada \"tickets.csv\" no PostgreSQL\n",
    "inserir_dataframe_postgres(df_tickets, \"tickets\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
