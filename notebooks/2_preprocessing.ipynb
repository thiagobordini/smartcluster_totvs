{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5322ee1e",
   "metadata": {},
   "source": [
    "#### **Setup Python**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ec1e93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação - Bibliotecas Python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, time, datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "import unicodedata\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Remoção de avisos do Python\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c45a74e",
   "metadata": {},
   "source": [
    "#### **Variáveis - Data Preprocessing TOTVS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c4ada0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável que armazena o caminho (path) das bases de dados presentes na camada raw\n",
    "path_raw = \"../data/raw\"\n",
    "\n",
    "# Variável que armazena o caminho (path) da camada \"processed\" onde as bases de dados processadas serão armazenadas inicialmente\n",
    "path_processed = \"../data/processed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2259ab",
   "metadata": {},
   "source": [
    "#### **Funções - Data Preprocessing TOTVS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06d982ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para padronizar strings: maiúsculas, remover acentos e espaços extras\n",
    "def padronizar_texto(coluna):\n",
    "    return (\n",
    "        coluna.astype(str)\n",
    "              .str.strip()\n",
    "              .str.upper()\n",
    "              .apply(lambda x: unicodedata.normalize(\"NFKD\", x)\n",
    "                      .encode(\"ascii\", errors=\"ignore\").decode(\"utf-8\"))\n",
    "    )\n",
    "\n",
    "# Função para calcular a idade em meses\n",
    "def idade_contrato_meses(data_assinatura):\n",
    "    if pd.isnull(data_assinatura):\n",
    "        return np.nan\n",
    "    delta = relativedelta(pd.Timestamp.today(), data_assinatura)\n",
    "    return delta.years * 12 + delta.months\n",
    "\n",
    "# Função que classifica a nota nps\n",
    "def classificar_nps(nota):\n",
    "    if nota >= 9:\n",
    "        return \"PROMOTOR\"\n",
    "    elif nota >= 7:\n",
    "        return \"NEUTRO\"\n",
    "    else:\n",
    "        return \"DETRATOR\"\n",
    "\n",
    "def inserir_dataframe_postgres(df, nome_tabela, if_exists='replace', chunksize=100000):\n",
    "    # Carrega variáveis de ambiente\n",
    "    load_dotenv(dotenv_path=\"../.env\")\n",
    "\n",
    "    # Dados de conexão\n",
    "    usuario = os.getenv('DB_USER')\n",
    "    senha = os.getenv('DB_PASSWORD')\n",
    "    host = os.getenv('DB_HOST')\n",
    "    porta = os.getenv('DB_PORT')\n",
    "    banco = os.getenv('DB_NAME')\n",
    "\n",
    "    # Verifica se as variáveis estão preenchidas\n",
    "    if None in [usuario, senha, host, porta, banco]:\n",
    "        raise ValueError(\"Alguma variável de ambiente do banco não está definida.\")\n",
    "\n",
    "    # Cria engine de conexão\n",
    "    conn_string = f'postgresql+psycopg2://{usuario}:{senha}@{host}:{porta}/{banco}'\n",
    "    engine = create_engine(conn_string)\n",
    "\n",
    "    # Envia o DataFrame para o banco\n",
    "    try:\n",
    "        df.to_sql(\n",
    "            name=nome_tabela,\n",
    "            con=engine,\n",
    "            if_exists=if_exists,\n",
    "            index=False,\n",
    "            chunksize=chunksize,\n",
    "            method='multi'  # mais eficiente para lotes\n",
    "        )\n",
    "        print(f\"Tabela '{nome_tabela}' inserida com sucesso!\")\n",
    "        print(f\"Total de linhas: {df.shape[0]:,} | Total de colunas: {df.shape[1]}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro ao inserir '{nome_tabela}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a2ee26",
   "metadata": {},
   "source": [
    "#### **Extract - Extração Dados Brutos (Raw)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a180325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura das bases de dados pertencentes há camada \"Row\"\n",
    "\n",
    "# Base de dados \"dados_clientes.csv\"\n",
    "dados_clientes = pd.read_csv(f\"{path_raw}/dados_clientes.csv\", sep=\";\")\n",
    "\n",
    "# Base de dados \"contratacoes_ultimos_12_meses.csv\"\n",
    "contratacoes = pd.read_csv(f\"{path_raw}/contratacoes_ultimos_12_meses.csv\", sep=\";\")\n",
    "\n",
    "# Base de dados \"clientes_desde.csv\"\n",
    "clientes_desde = pd.read_csv(f\"{path_raw}/clientes_desde.csv\", sep=\";\")\n",
    "\n",
    "# Base de dados \"historico.csv\"\n",
    "historico = pd.read_csv(f\"{path_raw}/historico.csv\", sep=\";\")\n",
    "\n",
    "# Base de dados \"mrr.csv\"\n",
    "mrr = pd.read_csv(f\"{path_raw}/mrr.csv\", sep=\";\")\n",
    "\n",
    "# Base de dados \"nps.nps_relacional.csv\"\n",
    "nps_relacional = pd.read_csv(f\"{path_raw}/nps_relacional.csv\", sep=';')\n",
    "\n",
    "# Base de dados \"nps_transacional_aquisicao.csv\"\n",
    "nps_aquisicao = pd.read_csv(f\"{path_raw}/nps_transacional_aquisicao.csv\", sep=\";\", encoding=\"latin1\")\n",
    "\n",
    "# Base de dados \"nps_transacional_implantacao.csv\"\n",
    "nps_implantacao = pd.read_csv(f\"{path_raw}/nps_transacional_implantacao.csv\", sep=\";\", encoding=\"latin1\")\n",
    "\n",
    "# Base de dados \"nps_transacional_onboarding.csv\"\n",
    "nps_onboarding = pd.read_csv(f\"{path_raw}/nps_transacional_onboarding.csv\", sep=\";\", encoding=\"latin1\")\n",
    "\n",
    "# Base de dados \"nps_transacional_produto.csv\"\n",
    "nps_produto = pd.read_csv(f\"{path_raw}/nps_transacional_produto.csv\", sep=\";\", encoding=\"latin1\")\n",
    "\n",
    "# Base de dados \"nps_transacional_suporte.csv\"\n",
    "nps_suporte = pd.read_csv(f\"{path_raw}/nps_transacional_suporte.csv\", sep=\";\")\n",
    "\n",
    "# Ordenação das bases de dados de \"telemetria_n.csv\"\n",
    "arquivos_telemetria = sorted(glob.glob(f\"{path_raw}/telemetria_*.csv\"))\n",
    "\n",
    "# Base de dados \"tickets.csv\"\n",
    "tickets = pd.read_csv(f\"{path_raw}/tickets.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004ab286",
   "metadata": {},
   "source": [
    "#### **Transform & Load - Pré-processamento dos dados para a camada \"Processed\" e PostgreSQL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82b4522",
   "metadata": {},
   "source": [
    "##### **Pré-processamento: dados_clientes.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797fe2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento da base de dados \"dados_clientes.csv\"\n",
    "\n",
    "# Cópia da base mãe\n",
    "df_dados_clientes = dados_clientes.copy(deep=True)\n",
    "\n",
    "# Aplicar nas colunas categóricas principais\n",
    "colunas_categoricas = [\n",
    "    \"DS_PROD\", \"DS_LIN_REC\", \"CIDADE\", \"DS_CNAE\", \"DS_SEGMENTO\",\n",
    "    \"DS_SUBSEGMENTO\", \"FAT_FAIXA\", \"MARCA_TOTVS\", \"MODAL_COMERC\",\n",
    "    \"PERIODICIDADE\", \"SITUACAO_CONTRATO\", \"UF\"\n",
    "]\n",
    "\n",
    "for col in colunas_categoricas:\n",
    "    df_dados_clientes[col] = padronizar_texto(df_dados_clientes[col])\n",
    "\n",
    "# Preenchimento de colunas com poucos nulos com 'NAO INFORMADO'\n",
    "colunas_para_preencher = {\n",
    "    \"DS_SUBSEGMENTO\": \"NAO INFORMADO\",\n",
    "    \"MARCA_TOTVS\": \"NAO INFORMADO\",\n",
    "    \"MODAL_COMERC\": \"NAO INFORMADO\",\n",
    "    \"PERIODICIDADE\": \"NAO INFORMADO\",\n",
    "    \"SITUACAO_CONTRATO\": \"NAO INFORMADO\"\n",
    "}\n",
    "\n",
    "for col, valor in colunas_para_preencher.items():\n",
    "    df_dados_clientes[col] = df_dados_clientes[col].fillna(valor)\n",
    "\n",
    "# Converter valor do contrato para float\n",
    "df_dados_clientes[\"VL_TOTAL_CONTRATO\"] = (\n",
    "    df_dados_clientes[\"VL_TOTAL_CONTRATO\"]\n",
    "    .replace(\"[R$ ]\", \"\", regex=True)\n",
    "    .str.replace(\".\", \"\", regex=False)\n",
    "    .str.replace(\",\", \".\", regex=False)\n",
    "    .astype(float)\n",
    "    .round(2)\n",
    ")\n",
    "\n",
    "# Faixas de Valor do Contrato\n",
    "bins = [-float(\"inf\"), 0, 10000, 50000, 100000, 500000, 1000000, float(\"inf\")]\n",
    "labels = [\"ZERADO/NEGATIVO\", \"ATE 10K\", \"10K–50K\", \"50K–100K\", \"100K–500K\", \"500K–1M\", \"ACIMA DE 1M\"]\n",
    "df_dados_clientes[\"VL_TOTAL_CONTRATO_FAIXA\"] = pd.cut(df_dados_clientes[\"VL_TOTAL_CONTRATO\"], bins=bins, labels=labels)\n",
    "\n",
    "# Converter data de assinatura para datetime\n",
    "df_dados_clientes[\"DT_ASSINATURA_CONTRATO\"] = pd.to_datetime(df_dados_clientes[\"DT_ASSINATURA_CONTRATO\"], errors=\"coerce\")\n",
    "\n",
    "# Ano e mês de assinatura\n",
    "df_dados_clientes[\"ANO_ASSINATURA\"] = df_dados_clientes[\"DT_ASSINATURA_CONTRATO\"].dt.year.astype('int64')\n",
    "df_dados_clientes[\"MES_ASSINATURA\"] = df_dados_clientes[\"DT_ASSINATURA_CONTRATO\"].dt.month.astype('int64')\n",
    "\n",
    "# Idade do contrato (em meses)\n",
    "df_dados_clientes[\"IDADE_CONTRATO_MESES\"] = df_dados_clientes[\"DT_ASSINATURA_CONTRATO\"].apply(idade_contrato_meses)\n",
    "\n",
    "# Renomear colunas para padrão snake_case\n",
    "df_dados_clientes.rename(columns={\n",
    "    \"CD_CLIENTE\": \"cliente_id\",\n",
    "    \"DS_PROD\": \"produto\",\n",
    "    \"DS_LIN_REC\": \"linha_receita\",\n",
    "    \"CIDADE\": \"cidade\",\n",
    "    \"DS_CNAE\": \"cnae\",\n",
    "    \"DS_SEGMENTO\": \"segmento\",\n",
    "    \"DS_SUBSEGMENTO\": \"subsegmento\",\n",
    "    \"FAT_FAIXA\": \"faixa_faturamento\",\n",
    "    \"MARCA_TOTVS\": \"marca_totvs\",\n",
    "    \"MODAL_COMERC\": \"modalidade_comercial\",\n",
    "    \"PAIS\": \"pais\",\n",
    "    \"PERIODICIDADE\": \"periodicidade\",\n",
    "    \"SITUACAO_CONTRATO\": \"situacao_contrato\",\n",
    "    \"UF\": \"uf\",\n",
    "    \"VL_TOTAL_CONTRATO\": \"valor_total_contrato\",\n",
    "    \"VL_TOTAL_CONTRATO_FAIXA\": \"faixa_valor_total_contrato\",\n",
    "    \"DT_ASSINATURA_CONTRATO\": \"data_assinatura_contrato\",\n",
    "    \"ANO_ASSINATURA\": \"ano_assinatura\",\n",
    "    \"MES_ASSINATURA\": \"mes_assinatura\",\n",
    "    \"IDADE_CONTRATO_MESES\": \"idade_contrato_meses\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Reorganizar colunas\n",
    "ordem_colunas = [\n",
    "    \"cliente_id\", \"produto\", \"linha_receita\", \"cnae\", \"segmento\", \"subsegmento\",\n",
    "    \"faixa_faturamento\", \"marca_totvs\", \"modalidade_comercial\", \"periodicidade\",\n",
    "    \"situacao_contrato\", \"cidade\", \"uf\", \"pais\",\n",
    "    \"valor_total_contrato\", \"faixa_valor_total_contrato\",\n",
    "    \"data_assinatura_contrato\", \"ano_assinatura\", \"mes_assinatura\", \"idade_contrato_meses\"\n",
    "]\n",
    "df_dados_clientes = df_dados_clientes[ordem_colunas]\n",
    "\n",
    "# Exportação da base tratada\n",
    "df_dados_clientes.to_csv(f\"{path_processed}/dados_clientes.csv\", index=False)\n",
    "\n",
    "# Carregamento base de dados processada \"dados_clientes.csv\" no PostreSQL\n",
    "inserir_dataframe_postgres(df_dados_clientes, \"dados_clientes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5246dd4a",
   "metadata": {},
   "source": [
    "##### **Pré-processamento: contratacoes_ultimos_12_meses.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a63e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento da base de dados \"contratacoes_ultimos_12_meses.csv\"\n",
    "\n",
    "# Cópia da base mãe\n",
    "df_contratacoes = contratacoes.copy(deep=True)\n",
    "\n",
    "# Conversão do valor para float\n",
    "df_contratacoes[\"VLR_CONTRATACOES_12M\"] = (\n",
    "    df_contratacoes[\"VLR_CONTRATACOES_12M\"]\n",
    "    .replace(\"[R$ ]\", \"\", regex=True)\n",
    "    .str.replace(\".\", \"\", regex=False)\n",
    "    .str.replace(\",\", \".\", regex=False)\n",
    "    .astype(float)\n",
    "    .round(2)\n",
    ")\n",
    "\n",
    "# Renomear colunas para padrão snake_case\n",
    "df_contratacoes.rename(columns={\n",
    "    \"CD_CLIENTE\": \"cliente_id\",\n",
    "    \"QTD_CONTRATACOES_12M\": \"qtd_contratacoes_12m\",\n",
    "    \"VLR_CONTRATACOES_12M\": \"vlr_contratacoes_12m\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Reorganizar colunas\n",
    "df_contratacoes = df_contratacoes[[\"cliente_id\", \"qtd_contratacoes_12m\", \"vlr_contratacoes_12m\"]]\n",
    "\n",
    "# Exportar base tratada\n",
    "df_contratacoes.to_csv(f\"{path_processed}/contratacoes_ultimos_12_meses.csv\", index=False)\n",
    "\n",
    "# Carregamento base de dados processada \"contratacoes_ultimos_12_meses.csv\" no PostreSQL\n",
    "inserir_dataframe_postgres(df_contratacoes, \"contratacoes_ultimos_12_meses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e67931e",
   "metadata": {},
   "source": [
    "##### **Pré-processamento: clientes_desde.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697d591b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento da base de dados \"clientes_desde.csv\"\n",
    "\n",
    "# Cópia da base mãe\n",
    "df_clientes_desde = clientes_desde.copy(deep=True)\n",
    "\n",
    "# Renomear colunas\n",
    "df_clientes_desde.rename(columns={\n",
    "    \"CLIENTE\": \"cliente_id\",\n",
    "    \"CLIENTE_DESDE\": \"cliente_desde\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Converter data\n",
    "df_clientes_desde[\"cliente_desde\"] = pd.to_datetime(df_clientes_desde[\"cliente_desde\"], errors=\"coerce\")\n",
    "\n",
    "# Criar colunas derivadas\n",
    "df_clientes_desde[\"ano_inicio\"] = df_clientes_desde[\"cliente_desde\"].dt.year.astype('int64')\n",
    "df_clientes_desde[\"tempo_com_empresa_anos\"] = (\n",
    "    (pd.Timestamp(\"today\") - df_clientes_desde[\"cliente_desde\"]).dt.days / 365\n",
    ").round(1)\n",
    "\n",
    "# Reorganizar colunas\n",
    "df_clientes_desde = df_clientes_desde[[\n",
    "    \"cliente_id\", \"cliente_desde\", \"ano_inicio\", \"tempo_com_empresa_anos\"\n",
    "]]\n",
    "\n",
    "# Exportar base tratada\n",
    "df_clientes_desde.to_csv(f\"{path_processed}/clientes_desde.csv\", index=False)\n",
    "\n",
    "# Carregamento base de dados processada \"clientes_desde.csv\" no PostreSQL\n",
    "inserir_dataframe_postgres(df_clientes_desde, \"clientes_desde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29143f0b",
   "metadata": {},
   "source": [
    "##### **Pré-processamento: historico.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46b10aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento da base de dados \"historico.csv\"\n",
    "\n",
    "# Cópia da base mãe\n",
    "df_historico = historico.copy(deep=True)\n",
    "\n",
    "# Renomeação de colunas\n",
    "df_historico.rename(columns={\n",
    "    \"NR_PROPOSTA\": \"nr_proposta\",\n",
    "    \"ITEM_PROPOSTA\": \"item_proposta\",\n",
    "    \"DT_UPLOAD\": \"data_upload\",\n",
    "    \"HOSPEDAGEM\": \"hospedagem\",\n",
    "    \"CD_CLI\": \"cliente_id\",\n",
    "    \"FAT_FAIXA\": \"faixa_faturamento\",\n",
    "    \"CD_PROD\": \"produto_id\",\n",
    "    \"QTD\": \"quantidade\",\n",
    "    \"MESES_BONIF\": \"meses_bonificacao\",\n",
    "    \"VL_PCT_DESC_TEMP\": \"pct_desc_temp\",\n",
    "    \"VL_PCT_DESCONTO\": \"pct_desconto\",\n",
    "    \"PRC_UNITARIO\": \"preco_unitario\",\n",
    "    \"VL_DESCONTO_TEMPORARIO\": \"valor_desc_temp\",\n",
    "    \"VL_TOTAL\": \"valor_total\",\n",
    "    \"VL_FULL\": \"valor_full\",\n",
    "    \"VL_DESCONTO\": \"valor_desconto\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Padronização de textos\n",
    "colunas_categoricas = [\"faixa_faturamento\", \"hospedagem\"]\n",
    "for col in colunas_categoricas:\n",
    "    df_historico[col] = padronizar_texto(df_historico[col])\n",
    "\n",
    "# Conversão de data\n",
    "df_historico[\"data_upload\"] = pd.to_datetime(df_historico[\"data_upload\"], errors=\"coerce\")\n",
    "df_historico[\"ano_upload\"] = df_historico[\"data_upload\"].dt.year.astype('int64')\n",
    "df_historico[\"mes_upload\"] = df_historico[\"data_upload\"].dt.month.astype('int64')\n",
    "\n",
    "# Conversão de valores numéricos\n",
    "colunas_valores = [\n",
    "    \"quantidade\", \"pct_desc_temp\", \"pct_desconto\", \"preco_unitario\",\n",
    "    \"valor_desc_temp\", \"valor_total\", \"valor_full\", \"valor_desconto\"\n",
    "]\n",
    "\n",
    "for col in colunas_valores:\n",
    "    df_historico[col] = (\n",
    "        df_historico[col]\n",
    "        .replace(\"[R$ ]\", \"\", regex=True)\n",
    "        .str.replace(\".\", \"\", regex=False)\n",
    "        .str.replace(\",\", \".\", regex=False)\n",
    "        .astype(float)\n",
    "        .round(2)\n",
    "    )\n",
    "\n",
    "# Reorganizar colunas (exemplo)\n",
    "colunas_ordenadas = [\n",
    "    \"nr_proposta\", \"item_proposta\", \"cliente_id\", \"produto_id\", \"data_upload\", \"ano_upload\", \"mes_upload\",\n",
    "    \"hospedagem\", \"faixa_faturamento\", \"quantidade\", \"meses_bonificacao\",\n",
    "    \"pct_desc_temp\", \"pct_desconto\", \"preco_unitario\", \"valor_desc_temp\",\n",
    "    \"valor_total\", \"valor_full\", \"valor_desconto\"\n",
    "]\n",
    "df_historico = df_historico[colunas_ordenadas]\n",
    "\n",
    "# Exportar base tratada\n",
    "df_historico.to_csv(f\"{path_processed}/historico.csv\", index=False)\n",
    "\n",
    "# Carregamento base de dados processada \"historico.csv\" no PostreSQL\n",
    "inserir_dataframe_postgres(df_historico, \"historico\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba18a3d",
   "metadata": {},
   "source": [
    "##### **Pré-processamento: mrr.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3403b790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento da base de dados \"mrr.csv\"\n",
    "\n",
    "# Cópia da base mãe\n",
    "df_mrr = mrr.copy(deep=True)\n",
    "\n",
    "# Renomear colunas\n",
    "df_mrr.rename(columns={\n",
    "    \"CLIENTE\": \"cliente_id\",\n",
    "    \"MRR_12M\": \"mrr_12m\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Arredondar MRR para 2 casas decimais\n",
    "df_mrr[\"mrr_12m\"] = df_mrr[\"mrr_12m\"].round(2)\n",
    "\n",
    "# Criar faixas de MRR (ajustável com base na distribuição real)\n",
    "bins = [-0.01, 0, 1000, 5000, 10000, 50000, 100000, float(\"inf\")]\n",
    "labels = [\"ZERADO\", \"ATE 1K\", \"1K–5K\", \"5K–10K\", \"10K–50K\", \"50K–100K\", \"ACIMA DE 100K\"]\n",
    "\n",
    "df_mrr[\"faixa_mrr_12m\"] = pd.cut(df_mrr[\"mrr_12m\"], bins=bins, labels=labels)\n",
    "\n",
    "# Reorganizar colunas\n",
    "df_mrr = df_mrr[[\"cliente_id\", \"mrr_12m\", \"faixa_mrr_12m\"]]\n",
    "\n",
    "# Exportar base tratada\n",
    "df_mrr.to_csv(f\"{path_processed}/mrr.csv\", index=False)\n",
    "\n",
    "# Carregamento base de dados processada \"mrr.csv\" no PostreSQL\n",
    "inserir_dataframe_postgres(df_mrr, \"mrr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced84609",
   "metadata": {},
   "source": [
    "##### **Pré-processamento: nps_relacional.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c7c624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento da base de dados \"nps_relacional.csv\"\n",
    "\n",
    "# Cópia da base mãe\n",
    "df_nps_relacional = nps_relacional.copy(deep=True)\n",
    "\n",
    "# Renomear colunas para padrão snake_case\n",
    "df_nps_relacional.rename(columns={\n",
    "    \"respondedAt\": \"data_resposta\",\n",
    "    \"metadata_codcliente\": \"cliente_id\",\n",
    "    \"resposta_NPS\": \"nota_nps\",\n",
    "    \"resposta_unidade\": \"nota_unidade\",\n",
    "    \"Nota_SupTec_Agilidade\": \"nota_suptec_agilidade\",\n",
    "    \"Nota_SupTec_Atendimento\": \"nota_suptec_atendimento\",\n",
    "    \"Nota_Comercial\": \"nota_comercial\",\n",
    "    \"Nota_Custos\": \"nota_custos\",\n",
    "    \"Nota_AdmFin_Atendimento\": \"nota_admfin_atendimento\",\n",
    "    \"Nota_Software\": \"nota_software\",\n",
    "    \"Nota_Software_Atualizacao\": \"nota_software_atualizacao\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Conversão de tipos\n",
    "df_nps_relacional[\"data_resposta\"] = pd.to_datetime(df_nps_relacional[\"data_resposta\"], errors=\"coerce\")\n",
    "df_nps_relacional[\"cliente_id\"] = df_nps_relacional[\"cliente_id\"].astype(str)\n",
    "df_nps_relacional[\"nota_nps\"] = df_nps_relacional[\"nota_nps\"].astype('int64')\n",
    "\n",
    "# Classificação da nota nps\n",
    "df_nps_relacional[\"categoria_nps\"] = df_nps_relacional[\"nota_nps\"].apply(classificar_nps)\n",
    "\n",
    "# Demais colunas de nota: garantir float\n",
    "notas_colunas = [\n",
    "    \"nota_unidade\", \"nota_suptec_agilidade\", \"nota_suptec_atendimento\",\n",
    "    \"nota_comercial\", \"nota_custos\", \"nota_admfin_atendimento\",\n",
    "    \"nota_software\", \"nota_software_atualizacao\"\n",
    "]\n",
    "df_nps_relacional[notas_colunas] = df_nps_relacional[notas_colunas].astype(float)\n",
    "\n",
    "# Exportar base tratada\n",
    "df_nps_relacional.to_csv(f\"{path_processed}/nps_relacional.csv\", index=False)\n",
    "\n",
    "# Carregamento base de dados processada \"nps_relacional.csv\" df_clientes\n",
    "inserir_dataframe_postgres(df_nps_relacional, \"nps_relacional\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26696cf5",
   "metadata": {},
   "source": [
    "##### **Pré-processamento: nps_transacional_aquisicao.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfdcd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento da base de dados \"nps_transacional_aquisicao.csv\"\n",
    "\n",
    "# Cópia da base mãe\n",
    "df_nps_aquisicao = nps_aquisicao.copy(deep=True)\n",
    "\n",
    "# Renomear colunas para padrão snake_case\n",
    "df_nps_aquisicao.rename(columns={\n",
    "    \"Cód. Cliente\": \"cliente_id\",\n",
    "    \"Data da Resposta\": \"data_resposta\",\n",
    "    \"Nota NPS\": \"nota_nps\",\n",
    "    \"Nota Agilidade\": \"nota_agilidade\",\n",
    "    \"Nota Conhecimento\": \"nota_conhecimento\",\n",
    "    \"Nota Custo\": \"nota_custo\",\n",
    "    \"Nota Facilidade\": \"nota_facilidade\",\n",
    "    \"Nota Flexibilidade\": \"nota_flexibilidade\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Preencher valor nulo em cliente_id\n",
    "df_nps_aquisicao[\"cliente_id\"] = df_nps_aquisicao[\"cliente_id\"].fillna(\"NAO INFORMADO\").astype(str)\n",
    "\n",
    "# Conversão de tipos\n",
    "df_nps_aquisicao[\"data_resposta\"] = pd.to_datetime(df_nps_aquisicao[\"data_resposta\"], errors=\"coerce\")\n",
    "df_nps_aquisicao[\"nota_nps\"] = df_nps_aquisicao[\"nota_nps\"].astype('int64')\n",
    "\n",
    "df_nps_aquisicao[\"categoria_nps\"] = df_nps_aquisicao[\"nota_nps\"].apply(classificar_nps)\n",
    "\n",
    "# Garantir float nas colunas de nota\n",
    "col_notas = [\n",
    "    \"nota_agilidade\", \"nota_conhecimento\", \"nota_custo\",\n",
    "    \"nota_facilidade\", \"nota_flexibilidade\"\n",
    "]\n",
    "df_nps_aquisicao[col_notas] = df_nps_aquisicao[col_notas].astype(float)\n",
    "\n",
    "# Exportar base tratada\n",
    "df_nps_aquisicao.to_csv(f\"{path_processed}/nps_transacional_aquisicao.csv\", index=False)\n",
    "\n",
    "# Carregamento base de dados processada \"nps_transacional_aquisicao.csv\"\n",
    "inserir_dataframe_postgres(df_nps_aquisicao, \"nps_transacional_aquisicao\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4972efe1",
   "metadata": {},
   "source": [
    "##### **Pré-processamento: nps_transacional_implantacao.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4705478a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento da base de dados \"nps_transacional_implantacao.csv\"\n",
    "\n",
    "# Cópia da base mãe\n",
    "df_nps_implatacao = nps_implantacao.copy(deep=True)\n",
    "\n",
    "# Renomear colunas para padrão snake_case\n",
    "df_nps_implatacao.rename(columns={\n",
    "    \"Cód. Cliente\": \"cliente_id\",\n",
    "    \"Data da Resposta\": \"data_resposta\",\n",
    "    \"Nota NPS\": \"nota_nps\",\n",
    "    \"Nota Metodologia\": \"nota_metodologia\",\n",
    "    \"Nota Gestao\": \"nota_gestao\",\n",
    "    \"Nota Conhecimento\": \"nota_conhecimento\",\n",
    "    \"Nota Qualidade\": \"nota_qualidade\",\n",
    "    \"Nota Comunicacao\": \"nota_comunicacao\",\n",
    "    \"Nota Prazos\": \"nota_prazos\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Preencher cliente_id nulo com 'NAO INFORMADO'\n",
    "df_nps_implatacao[\"cliente_id\"] = df_nps_implatacao[\"cliente_id\"].fillna(\"NAO INFORMADO\").astype(str)\n",
    "\n",
    "# Converter data e nota NPS\n",
    "df_nps_implatacao[\"data_resposta\"] = pd.to_datetime(df_nps_implatacao[\"data_resposta\"], errors=\"coerce\")\n",
    "df_nps_implatacao[\"nota_nps\"] = df_nps_implatacao[\"nota_nps\"].astype('int64')\n",
    "\n",
    "# Classificação de NPS\n",
    "df_nps_implatacao[\"categoria_nps\"] = df_nps_implatacao[\"nota_nps\"].apply(classificar_nps)\n",
    "\n",
    "# Garantir que demais colunas estejam como float\n",
    "col_notas = [\n",
    "    \"nota_metodologia\", \"nota_gestao\", \"nota_conhecimento\",\n",
    "    \"nota_qualidade\", \"nota_comunicacao\", \"nota_prazos\"\n",
    "]\n",
    "df_nps_implatacao[col_notas] = df_nps_implatacao[col_notas].astype(float)\n",
    "\n",
    "# Exportar base tratada\n",
    "df_nps_implatacao.to_csv(f\"{path_processed}/nps_transacional_implantacao.csv\", index=False)\n",
    "\n",
    "# Carregamento base de dados processada \"nps_transacional_implantacao.csv\" no PostgreSQL\n",
    "inserir_dataframe_postgres(df_nps_implatacao, \"nps_transacional_implantacao\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8a37a3",
   "metadata": {},
   "source": [
    "##### **Pré-processamento: nps_transacional_onboarding.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586f7e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento da base de dados \"nps_transacional_onboarding.csv\"\n",
    "\n",
    "# Cópia da base mãe\n",
    "df_nps_onboarding = nps_onboarding.copy(deep=True)\n",
    "\n",
    "# Renomear colunas para snake_case e nomes mais limpos\n",
    "df_nps_onboarding.rename(columns={\n",
    "    \"Data de resposta\": \"data_resposta\",\n",
    "    \"Cod Cliente\": \"cliente_id\",\n",
    "    \"Em uma escala de 0 a 10, quanto você recomenda o Onboarding da TOTVS para um amigo ou colega?.\": \"nota_nps\",\n",
    "    \"Em uma escala de 0 a 10, o quanto você acredita que o atendimento CS Onboarding ajudou no início da sua trajetória com a TOTVS?\": \"nota_ajuda_inicio\",\n",
    "    \"- Duração do tempo na realização da reunião de Onboarding;\": \"nota_tempo_reuniao\",\n",
    "    \"- Clareza no acesso aos canais de comunicação da TOTVS;\": \"nota_clareza_comunicacao\",\n",
    "    \"- Clareza nas informações em geral transmitidas pelo CS que lhe atendeu no Onboarding;\": \"nota_clareza_informacao\",\n",
    "    \"- Expectativas atendidas no Onboarding da TOTVS.\": \"nota_expectativa\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Preencher cliente_id nulo com 'NAO INFORMADO'\n",
    "df_nps_onboarding[\"cliente_id\"] = df_nps_onboarding[\"cliente_id\"].fillna(\"NAO INFORMADO\").astype(str)\n",
    "\n",
    "# Converter data\n",
    "df_nps_onboarding[\"data_resposta\"] = pd.to_datetime(df_nps_onboarding[\"data_resposta\"], errors=\"coerce\")\n",
    "\n",
    "# Garantir que nota_nps seja int\n",
    "df_nps_onboarding[\"nota_nps\"] = df_nps_onboarding[\"nota_nps\"].astype('int64')\n",
    "\n",
    "# Criar categoria NPS\n",
    "df_nps_onboarding[\"categoria_nps\"] = df_nps_onboarding[\"nota_nps\"].apply(classificar_nps)\n",
    "\n",
    "# Garantir que demais notas sejam float\n",
    "colunas_float = [\n",
    "    \"nota_ajuda_inicio\", \"nota_tempo_reuniao\", \"nota_clareza_comunicacao\",\n",
    "    \"nota_clareza_informacao\", \"nota_expectativa\"\n",
    "]\n",
    "df_nps_onboarding[colunas_float] = df_nps_onboarding[colunas_float].astype(float)\n",
    "\n",
    "# Exportar base tratada\n",
    "df_nps_onboarding.to_csv(f\"{path_processed}/nps_transacional_onboarding.csv\", index=False)\n",
    "\n",
    "# Carregamento base de dados processada \"nps_transacional_onboarding.csv\" no PostgreSQL\n",
    "inserir_dataframe_postgres(df_nps_onboarding, \"nps_transacional_onboarding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2077e6",
   "metadata": {},
   "source": [
    "##### **Pré-processamento: nps_transacional_produto.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81822045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento da base de dados \"nps_transacional_produto.csv\"\n",
    "\n",
    "# Cópia da base mãe\n",
    "df_nps_produto = nps_produto.copy(deep=True)\n",
    "\n",
    "# Renomear colunas\n",
    "df_nps_produto.rename(columns={\n",
    "    \"Data da Resposta\": \"data_resposta\",\n",
    "    \"Linha de Produto\": \"linha_produto\",\n",
    "    \"Nome do Produto\": \"nome_produto\",\n",
    "    \"Nota\": \"nota_nps\",\n",
    "    \"Cód. T\": \"cliente_id\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Converter data\n",
    "df_nps_produto[\"data_resposta\"] = pd.to_datetime(df_nps_produto[\"data_resposta\"], errors=\"coerce\")\n",
    "\n",
    "# Padronizar colunas de texto (linha e nome do produto)\n",
    "df_nps_produto[\"linha_produto\"] = padronizar_texto(df_nps_produto[\"linha_produto\"])\n",
    "df_nps_produto[\"nome_produto\"] = padronizar_texto(df_nps_produto[\"nome_produto\"])\n",
    "\n",
    "# Garantir que cliente_id seja string\n",
    "df_nps_produto[\"cliente_id\"] = df_nps_produto[\"cliente_id\"].astype(str)\n",
    "\n",
    "# Garantir nota como int\n",
    "df_nps_produto[\"nota_nps\"] = df_nps_produto[\"nota_nps\"].astype('int64')\n",
    "\n",
    "# Classificação de NPS\n",
    "df_nps_produto[\"categoria_nps\"] = df_nps_produto[\"nota_nps\"].apply(classificar_nps)\n",
    "\n",
    "# Exportar base tratada\n",
    "df_nps_produto.to_csv(f\"{path_processed}/nps_transacional_produto.csv\", index=False)\n",
    "\n",
    "# Carregamento base de dados processada \"nps_transacional_produto.csv\" no PostgreSQL\n",
    "inserir_dataframe_postgres(df_nps_produto, \"nps_transacional_produto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde509a5",
   "metadata": {},
   "source": [
    "##### **Pré-processamento: nps_transacional_suporte.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8117f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento da base de dados \"nps_transacional_suporte.csv\"\n",
    "\n",
    "# Cópia da base mãe\n",
    "df_nps_suporte = nps_suporte.copy(deep=True)\n",
    "\n",
    "# Renomear colunas\n",
    "df_nps_suporte.rename(columns={\n",
    "    \"ticket\": \"ticket_id\",\n",
    "    \"resposta_NPS\": \"nota_nps\",\n",
    "    \"grupo_NPS\": \"categoria_nps\",\n",
    "    \"Nota_ConhecimentoAgente\": \"nota_conhecimento_agente\",\n",
    "    \"Nota_Solucao\": \"nota_solucao\",\n",
    "    \"Nota_TempoRetorno\": \"nota_tempo_retorno\",\n",
    "    \"Nota_Facilidade\": \"nota_facilidade\",\n",
    "    \"Nota_Satisfacao\": \"nota_satisfacao\",\n",
    "    \"cliente\": \"cliente_id\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Padronizar a categoria NPS\n",
    "df_nps_suporte[\"categoria_nps\"] = df_nps_suporte[\"categoria_nps\"].str.upper().str.strip()\n",
    "df_nps_suporte[\"categoria_nps\"] = df_nps_suporte[\"categoria_nps\"].replace(\"PASSIVO\", \"NEUTRO\")\n",
    "\n",
    "\n",
    "# Garantir tipos consistentes\n",
    "df_nps_suporte[\"ticket_id\"] = df_nps_suporte[\"ticket_id\"].astype('int64')\n",
    "df_nps_suporte[\"nota_nps\"] = df_nps_suporte[\"nota_nps\"].astype('int64')\n",
    "df_nps_suporte[\"cliente_id\"] = df_nps_suporte[\"cliente_id\"].astype(str)\n",
    "\n",
    "# Exportar base tratada\n",
    "df_nps_suporte.to_csv(f\"{path_processed}/nps_transacional_suporte.csv\", index=False)\n",
    "\n",
    "# Carregamento base de dados processada \"nps_transacional_suporte.csv\" no PostgreSQL\n",
    "inserir_dataframe_postgres(df_nps_suporte, \"nps_transacional_suporte\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d51f3e4",
   "metadata": {},
   "source": [
    "##### **Pré-processamento: telemetria_1.csv a telemetria_11.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f504161e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento das bases de dados \"telemetria_n.csv\"\n",
    "\n",
    "for arquivo_telemetria in arquivos_telemetria:\n",
    "    df_telemetria = pd.read_csv(arquivo_telemetria)\n",
    "\n",
    "    # Conversão de datas\n",
    "    df_telemetria['referencedatestart'] = pd.to_datetime(df_telemetria['referencedatestart'], errors='coerce')\n",
    "\n",
    "    # Criar coluna de referência no formato YYYY e MM\n",
    "    df_telemetria[\"ano_referencia\"] = df_telemetria[\"referencedatestart\"].dt.year.astype('int64')\n",
    "    df_telemetria[\"mes_referencia\"] = df_telemetria[\"referencedatestart\"].dt.month.astype('int64')\n",
    "\n",
    "    # Padronização de texto\n",
    "    df_telemetria['statuslicenca'] = df_telemetria['statuslicenca'].astype(str).str.strip().str.upper()\n",
    "\n",
    "    # Preencher valores nulos em 'statuslicenca' com 'NAO INFORMADO'\n",
    "    df_telemetria['statuslicenca'] = df_telemetria['statuslicenca'].replace('NAN', np.nan)\n",
    "    df_telemetria['statuslicenca'] = df_telemetria['statuslicenca'].fillna('NAO INFORMADO')\n",
    "\n",
    "    # Remover colunas irrelevantes (tcloud e clienteprime, pois são totalmente nulas)\n",
    "    df_telemetria.drop(columns=['tcloud', 'clienteprime'], inplace=True)\n",
    "\n",
    "    # Renomeação de colunas\n",
    "    df_telemetria.rename(columns={\n",
    "        'clienteid': 'cliente_id',\n",
    "        'eventduration': 'duracao_evento',\n",
    "        'moduloid': 'modulo_id',\n",
    "        'productlineid': 'linha_produto_id',\n",
    "        'referencedatestart': 'data_referencia',\n",
    "        'slotid': 'slot_id',\n",
    "        'statuslicenca': 'status_licenca'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Reorganização das colunas\n",
    "    ordem_colunas = [\n",
    "        'cliente_id', 'data_referencia', 'ano_referencia', 'mes_referencia', 'duracao_evento',\n",
    "        'modulo_id', 'linha_produto_id', 'slot_id', 'status_licenca'\n",
    "    ]\n",
    "    df_telemetria = df_telemetria[ordem_colunas]\n",
    "\n",
    "    # Exportar base tratada\n",
    "    df_telemetria.to_csv(f\"{path_processed}/{arquivo_telemetria.split(\"\\\\\")[1]}\", index=False)\n",
    "    \n",
    "    # Carregamento base de dados processada \"telemetria_[n].csv\" no PostgreSQL\n",
    "    inserir_dataframe_postgres(df_telemetria, f\"telemetria_{re.findall(r'\\d+', arquivo_telemetria)[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e237e59a",
   "metadata": {},
   "source": [
    "##### **Pré-processamento: tickets.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9d3b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento da base de dados \"nps_transacional_suporte.csv\"\n",
    "\n",
    "# Cópia da base mãe\n",
    "df_tickets = tickets.copy(deep=True)\n",
    "\n",
    "# Conversão de datas\n",
    "df_tickets['DT_CRIACAO'] = pd.to_datetime(df_tickets['DT_CRIACAO'], errors='coerce')\n",
    "df_tickets['DT_ATUALIZACAO'] = pd.to_datetime(df_tickets['DT_ATUALIZACAO'], errors='coerce')\n",
    "\n",
    "# Criação de colunas de granularidade temporal\n",
    "df_tickets['ANO_CRIACAO'] = df_tickets['DT_CRIACAO'].dt.year.astype('int64')\n",
    "df_tickets['MES_CRIACAO'] = df_tickets['DT_CRIACAO'].dt.month.astype('int64')\n",
    "\n",
    "# Padronização de texto (strip + upper)\n",
    "colunas_texto = ['NOME_GRUPO', 'TIPO_TICKET', 'STATUS_TICKET', 'PRIORIDADE_TICKET']\n",
    "for col in colunas_texto:\n",
    "    df_tickets[col] = df_tickets[col].str.strip().str.upper().apply(lambda x: unicodedata.normalize(\"NFKD\", x).encode(\"ascii\", errors=\"ignore\").decode(\"utf-8\"))\n",
    "\n",
    "# Renomear colunas para snake_case\n",
    "df_tickets.rename(columns={\n",
    "    'CODIGO_ORGANIZACAO': 'codigo_organizacao',\n",
    "    'NOME_GRUPO': 'nome_grupo',\n",
    "    'TIPO_TICKET': 'tipo_ticket',\n",
    "    'STATUS_TICKET': 'status_ticket',\n",
    "    'DT_CRIACAO': 'data_criacao',\n",
    "    'DT_ATUALIZACAO': 'data_atualizacao',\n",
    "    'BK_TICKET': 'ticket_id',\n",
    "    'PRIORIDADE_TICKET': 'prioridade_ticket',\n",
    "    'ANO_CRIACAO': 'ano_criacao',\n",
    "    'MES_CRIACAO': 'mes_criacao'\n",
    "}, inplace=True)\n",
    "\n",
    "# Reorganização das colunas\n",
    "ordem_colunas = [\n",
    "    'ticket_id', 'codigo_organizacao', 'nome_grupo', 'tipo_ticket', 'status_ticket',\n",
    "    'prioridade_ticket', 'data_criacao', 'ano_criacao', 'mes_criacao', 'data_atualizacao'\n",
    "]\n",
    "df_tickets = df_tickets[ordem_colunas]\n",
    "\n",
    "# Exportação da base tratada\n",
    "df_tickets.to_csv(f\"{path_processed}/tickets.csv\", index=False)\n",
    "\n",
    "# Carregamento base de dados processada \"tickets.csv\" no PostgreSQL\n",
    "inserir_dataframe_postgres(df_tickets, \"tickets\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
